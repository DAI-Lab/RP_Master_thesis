{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook defines and implements the new metrics of my thesis for synthetic data assessment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and libraries mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import os.path\n",
    "from os import path as pa\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "from collections import Counter\n",
    "import scipy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA,FactorAnalysis\n",
    "from scipy.stats import ks_2samp,chisquare\n",
    "import torch\n",
    "import sys \n",
    "sys.path.append('../torch-two-sample')\n",
    "import json\n",
    "from torch_two_sample import MMDStatistic, EnergyStatistic,FRStatistic,KNNStatistic\n",
    "from scipy.spatial import Delaunay,ConvexHull\n",
    "sys.path.append('../DataShapley')\n",
    "from Shapley import ShapNN\n",
    "from DShap import DShap\n",
    "from shap_utils import *\n",
    "from preferencefig import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.spatial import ConvexHull\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M_FAMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with one dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading real and synthetic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dataset = 'witmer_census_1980_1'   # TODO : put dataset name. Ensure the path to the real and synthetic datasets are correct\n",
    "path_dataset = '../T_Data/'+name_dataset+'/Data/'+name_dataset\n",
    "X_r = pd.read_csv(path_dataset+'.csv',index_col = [0])\n",
    "X_s = pd.read_csv(path_dataset+'_GC.csv',index_col = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform PCA FAMD\n",
    "r_points and s_points are 2D array representing the projected real and synthetic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_r = FactorAnalysis(n_components=2)\n",
    "if len(X_r.columns)>2 :\n",
    "    r_points = fa_r.fit_transform(X_r)\n",
    "    s_points = fa_r.transform(X_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Intersection Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_r = ConvexHull(r_points)\n",
    "k_s = ConvexHull(s_points)\n",
    "\n",
    "x_r_1 = r_points[k_r.vertices,0]\n",
    "y_r_1 = r_points[k_r.vertices,1]\n",
    "x_r_1 = np.append(x_r_1,x_r_1[0])\n",
    "y_r_1 = np.append(y_r_1,y_r_1[0])\n",
    "area_r = Polygon(r_points[k_r.vertices]).area\n",
    "area_s = Polygon(s_points[k_s.vertices]).area\n",
    "\n",
    "eq_r = k_r.equations\n",
    "\n",
    "x_s_1 = s_points[k_s.vertices,0]\n",
    "y_s_1 = s_points[k_s.vertices,1]\n",
    "x_s_1 = np.append(x_s_1,x_s_1[0])\n",
    "y_s_1 = np.append(y_s_1,y_s_1[0])\n",
    "\n",
    "eq_s = k_s.equations\n",
    "eq_r_2 = np.stack((-eq_r[:,0]/eq_r[:,1],-eq_r[:,2]/eq_r[:,1]),axis=1)\n",
    "eq_s_2 = np.stack((-eq_s[:,0]/eq_s[:,1],-eq_s[:,2]/eq_s[:,1]),axis=1)\n",
    "\n",
    "x_intersection = np.zeros((len(eq_r_2)*len(eq_s_2))) \n",
    "y_intersection = np.zeros((len(eq_r_2)*len(eq_s_2))) \n",
    "\n",
    "for i in range(len(eq_r_2)) :\n",
    "    for j in range(len(eq_s_2)) : \n",
    "        x_intersection[i*len(eq_s_2)+j] = (eq_r_2[i,1]-eq_s_2[j,1])/(eq_s_2[j,0]-eq_r_2[i,0])\n",
    "        y_intersection[i*len(eq_s_2)+j] = eq_r_2[i,0]*x_intersection[i*len(eq_s_2)+j]+eq_r_2[i,1]\n",
    "import matplotlib.path as mplPath\n",
    "p_r = mplPath.Path(r_points[k_r.vertices])\n",
    "p_s = mplPath.Path(s_points[k_s.vertices])\n",
    "points = np.stack((x_intersection,y_intersection),axis=1)\n",
    "m1 = p_r.contains_points(points,radius = 0.00001)\n",
    "m2 = p_s.contains_points(points,radius = 0.00001)\n",
    "m3 = 1*m1+1*m2\n",
    "ind_int = np.where(m3==2)[0]\n",
    "x_int = points[ind_int,0]\n",
    "y_int = points[ind_int,1]\n",
    "mask_4 = np.zeros(len(x_r_1))\n",
    "mask_5 = np.zeros(len(x_s_1))\n",
    "\n",
    "point_r = np.stack((x_r_1,y_r_1),axis=1)\n",
    "point_s = np.stack((x_s_1,y_s_1),axis=1)\n",
    "m4 = p_r.contains_points(point_s,radius = 0.00001)\n",
    "m5 = p_s.contains_points(point_r,radius = 0.00001)\n",
    "point_r_int = point_s[m4]\n",
    "point_s_int = point_r[m5]\n",
    "\n",
    "x_f = np.concatenate((x_int,point_s_int[:,0],point_r_int[:,0]))\n",
    "y_f = np.concatenate((y_int,point_s_int[:,1],point_r_int[:,1]))\n",
    "p_int = np.stack((x_f,y_f),axis=1)\n",
    "k_int = ConvexHull(p_int)\n",
    "int_area = Polygon(p_int[k_int.vertices,:]).area\n",
    "x_f2 = x_f[k_int.vertices]\n",
    "y_f2 = y_f[k_int.vertices]\n",
    "x_f2 = np.append(x_f2,x_f2[0])\n",
    "y_f2 = np.append(y_f2,y_f2[0])\n",
    "\n",
    "union_point = np.concatenate((r_points,s_points),axis=0)\n",
    "k_union = ConvexHull(union_point)\n",
    "union_area = Polygon(union_point[k_union.vertices]).area\n",
    "m_famd = int_area/union_area\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Union area\n",
    "m_famd is the metric score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_point = np.concatenate((r_points,s_points),axis=0)\n",
    "k_union = ConvexHull(union_point)\n",
    "union_area = Polygon(union_point[k_union.vertices]).area\n",
    "m_famd = int_area/union_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(r_points[:,0],r_points[:,1],'r.')\n",
    "ax.plot(s_points[:,0],s_points[:,1],'b.')\n",
    "ax.plot(x_s_1,y_s_1,'b-')\n",
    "ax.plot(x_r_1,y_r_1,'r-')\n",
    "ax.plot(x_f2,y_f2,'g-')\n",
    "ax.plot(x_int,y_int,'+')\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_title('$M_{FAMD} $ Score : '+ str(np.round(m_famd,2)))\n",
    "fig.savefig('../Results/Result_11/Figures/PCA_1.jpeg',dpi=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to compute the M_FAMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pca_met(X_r,X_s):\n",
    "    '''\n",
    "    Method to compute M_FMAD metric.\n",
    "    First, the 2 prinicpal components are fitted.\n",
    "    Then, real and synthetic are projected according the two principal components. This gives real and synthetic data 2D scatter plots.\n",
    "    From the scatter plots, intersection and union area are computed. \n",
    "    Finally, the metric is the ratio between the intersection and the union.  \n",
    "\n",
    "    Input :\n",
    "\n",
    "    X_r : pandas dataframe, real dataset.\n",
    "    X_s : pandas dataframe, synthetic dataset.\n",
    "\n",
    "    Output : \n",
    "\n",
    "    m_famd : float, metric score\n",
    "\n",
    "    '''\n",
    "\n",
    "    fa_r = FactorAnalysis(n_components=2)\n",
    "    if len(X_r.columns)>2 :\n",
    "        r_points = fa_r.fit_transform(X_r)\n",
    "        s_points = fa_r.transform(X_s)\n",
    "    from shapely.geometry import Point, Polygon\n",
    "    k_r = ConvexHull(r_points)\n",
    "    k_s = ConvexHull(s_points)\n",
    "    \n",
    "    x_r_1 = r_points[k_r.vertices,0]\n",
    "    y_r_1 = r_points[k_r.vertices,1]\n",
    "    x_r_1 = np.append(x_r_1,x_r_1[0])\n",
    "    y_r_1 = np.append(y_r_1,y_r_1[0])\n",
    "    area_r = Polygon(r_points[k_r.vertices]).area\n",
    "    area_s = Polygon(s_points[k_s.vertices]).area\n",
    "\n",
    "    eq_r = k_r.equations\n",
    "\n",
    "    x_s_1 = s_points[k_s.vertices,0]\n",
    "    y_s_1 = s_points[k_s.vertices,1]\n",
    "    x_s_1 = np.append(x_s_1,x_s_1[0])\n",
    "    y_s_1 = np.append(y_s_1,y_s_1[0])\n",
    "\n",
    "    eq_s = k_s.equations\n",
    "    eq_r_2 = np.stack((-eq_r[:,0]/eq_r[:,1],-eq_r[:,2]/eq_r[:,1]),axis=1)\n",
    "    eq_s_2 = np.stack((-eq_s[:,0]/eq_s[:,1],-eq_s[:,2]/eq_s[:,1]),axis=1)\n",
    "\n",
    "    x_intersection = np.zeros((len(eq_r_2)*len(eq_s_2))) \n",
    "    y_intersection = np.zeros((len(eq_r_2)*len(eq_s_2))) \n",
    "\n",
    "    for i in range(len(eq_r_2)) :\n",
    "        for j in range(len(eq_s_2)) : \n",
    "            x_intersection[i*len(eq_s_2)+j] = (eq_r_2[i,1]-eq_s_2[j,1])/(eq_s_2[j,0]-eq_r_2[i,0])\n",
    "            y_intersection[i*len(eq_s_2)+j] = eq_r_2[i,0]*x_intersection[i*len(eq_s_2)+j]+eq_r_2[i,1]\n",
    "    import matplotlib.path as mplPath\n",
    "    p_r = mplPath.Path(r_points[k_r.vertices])\n",
    "    p_s = mplPath.Path(s_points[k_s.vertices])\n",
    "    points = np.stack((x_intersection,y_intersection),axis=1)\n",
    "    m1 = p_r.contains_points(points,radius = 0.00001)\n",
    "    m2 = p_s.contains_points(points,radius = 0.00001)\n",
    "    m3 = 1*m1+1*m2\n",
    "    ind_int = np.where(m3==2)[0]\n",
    "    x_int = points[ind_int,0]\n",
    "    y_int = points[ind_int,1]\n",
    "    mask_4 = np.zeros(len(x_r_1))\n",
    "    mask_5 = np.zeros(len(x_s_1))\n",
    "\n",
    "    point_r = np.stack((x_r_1,y_r_1),axis=1)\n",
    "    point_s = np.stack((x_s_1,y_s_1),axis=1)\n",
    "    m4 = p_r.contains_points(point_s,radius = 0.00001)\n",
    "    m5 = p_s.contains_points(point_r,radius = 0.00001)\n",
    "    point_r_int = point_s[m4]\n",
    "    point_s_int = point_r[m5]\n",
    "\n",
    "    x_f = np.concatenate((x_int,point_s_int[:,0],point_r_int[:,0]))\n",
    "    y_f = np.concatenate((y_int,point_s_int[:,1],point_r_int[:,1]))\n",
    "    p_int = np.stack((x_f,y_f),axis=1)\n",
    "    k_int = ConvexHull(p_int)\n",
    "    int_area = Polygon(p_int[k_int.vertices,:]).area\n",
    "    x_f2 = x_f[k_int.vertices]\n",
    "    y_f2 = y_f[k_int.vertices]\n",
    "    x_f2 = np.append(x_f2,x_f2[0])\n",
    "    y_f2 = np.append(y_f2,y_f2[0])\n",
    "    \n",
    "    area_int = k_int.area\n",
    "\n",
    "    union_point = np.concatenate((r_points,s_points),axis=0)\n",
    "    k_union = ConvexHull(union_point)\n",
    "    union_area = Polygon(union_point[k_union.vertices]).area\n",
    "    m_famd = int_area/union_area\n",
    "    return m_famd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of permutation for permutation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stat_test(X_r,X_s,names,num_perm=400):\n",
    "\n",
    "    '''\n",
    "    Method to compute new multivariate two samples statistical tests.\n",
    "\n",
    "    Inputs : \n",
    "\n",
    "    X_r = panda dataframe, real dataset.\n",
    "    X_s = panda dataframe, synthetic dataset. \n",
    "\n",
    "    names : list of string, list of the statistical test perform. \n",
    "            The different tests are 'ENE', 'KNN', 'MMD', 'FR'\n",
    "    \n",
    "    num_perm : integer, number of permutation for the permutation method to compute the p-value of the tests.\n",
    "\n",
    "    Output : \n",
    "\n",
    "    score : dictionary, the key is the name of the test and the value its score.\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    X_r = torch.tensor(X_r.values)\n",
    "    X_s = torch.tensor(X_s.values)\n",
    "    result = np.zeros(num_perm)\n",
    "    result_2 = np.zeros(num_perm)\n",
    "    size = int(0.5*len(X_r))\n",
    "    if len(X_r)%2==0 :\n",
    "        imp = False \n",
    "        n_1 = size\n",
    "        n_2 = size\n",
    "    else :\n",
    "        imp = True\n",
    "        n_1 = size\n",
    "        n_2 = size+1\n",
    "    dict_test = {'FR':FRStatistic(n_1,n_2),'KNN':KNNStatistic(n_1,n_2,5),'MMD':MMDStatistic(n_1,n_2),'ENE':EnergyStatistic(n_1,n_2)}\n",
    "    score = {}\n",
    "    \n",
    "    for n in names : \n",
    "        FRR = dict_test[n]\n",
    "        for i in range(num_perm): \n",
    "            mask = torch.randperm(len(X_r))\n",
    "            mask2 = torch.randperm(len(X_s))\n",
    "            \n",
    "            X_r1 = X_r[mask[:size],:]\n",
    "            X_r2 = X_r[mask[size:],:]\n",
    "            if not imp : \n",
    "                X_s2 = X_s[mask2[:size],:]\n",
    "            else :\n",
    "                X_s2 = X_s[mask2[:size+1],:]\n",
    "            if n == 'MMD' : \n",
    "                result[i] = FRR(X_r1,X_r2,alphas=[1,1],ret_matrix=False)\n",
    "                result_2[i] = FRR(X_r1,X_s2,alphas=[1,1],ret_matrix=False)\n",
    "            else :\n",
    "                result[i] = FRR(X_r1,X_r2,ret_matrix=False)\n",
    "                result_2[i] = FRR(X_r1,X_s2,ret_matrix=False)\n",
    "        b_s = result_2.mean()\n",
    "        pvalue = np.sum(b_s<result)/num_perm\n",
    "        m = (1-2*0.1)/(0.1**2)\n",
    "        score[n] = np.log(m*pvalue+1)/np.log(m+1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M_SHAP metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_M_shap(X_r,X_test,X_s) : \n",
    "    ''' \n",
    "    Method to compute M_SHAP metric.\n",
    "\n",
    "\n",
    "    Inputs : \n",
    "    \n",
    "    X_r  : panda dataframe, real dataset use in the training.\n",
    "    X_test : panda dataframe, real dataset used for testing.\n",
    "    X_s : panda dataframe, synthetic dataset. \n",
    "\n",
    "    Output : \n",
    "\n",
    "    score : float, M_SHAP.\n",
    "    \n",
    "    '''\n",
    "    problem, model = 'classification', 'logistic'\n",
    "    X = pd.concat([X_r,X_s],axis=0,ignore_index=True)\n",
    "    y_test = X_test['class'].values.astype('int')\n",
    "    X_test = X_test.drop('class',axis=1)\n",
    "    X_test = X_test.values\n",
    "    y = X['class'].values.astype('int')\n",
    "    X = X.drop('class',axis=1)\n",
    "    X = X.values\n",
    "    num_test = 1000\n",
    "    directory2 = 'Shapley/Exp_1/' #'../Result_03/Data/Shapley_3/'\n",
    "    dshap = DShap(X, y, X_test, y_test, num_test, \n",
    "                sources=None, \n",
    "                sample_weight=None,\n",
    "                model_family=model, \n",
    "                metric='accuracy',\n",
    "                overwrite=True,\n",
    "                directory=directory2, seed=0)\n",
    "    dshap.run(100, 0.1, g_run=False)\n",
    "    vals_tmc_good = pd.Series(dshap.vals_tmc)\n",
    "    v1 = vals_tmc_good\n",
    "    m_1 = v1[v1.index<int(0.5*len(X))]\n",
    "    m_2 = v1[v1.index>int(0.5*len(X))]\n",
    "    min_t = np.minimum(np.min(m_1),np.min(m_2))\n",
    "    max_t = np.maximum(np.max(m_1),np.max(m_2))\n",
    "    m_11s = (m_1-min_t)/(max_t-min_t)\n",
    "    m_22s = (m_2-min_t)/(max_t-min_t)\n",
    "    m2_m = m_22s.mean()\n",
    "    m1_m = m_11s.mean()\n",
    "    mm = (1-2*m1_m)/(m1_m**2)\n",
    "    score = np.log(mm*m2_m+1)/np.log(mm+1)\n",
    "    return score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('master_thesis_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb94901783c70338e2565c51f5548ab85eea424b621152c27cc477f4c97d257c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
